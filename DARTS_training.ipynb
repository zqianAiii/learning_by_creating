{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from DARTS_model import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "image_size = 32\n",
    "label_dim = 10\n",
    "G_in_dim = 100\n",
    "G_out_dim = 3\n",
    "D_in_dim = 3\n",
    "D_out_dim = 1\n",
    "num_channels = [512, 256, 128]\n",
    "\n",
    "learning_rate = 0.0002\n",
    "betas = (0.5, 0.999)\n",
    "batch_size = 16\n",
    "num_epochs = 150\n",
    "save_dir = '/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = tv.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [len(trainset)//2, len(trainset)//2])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "testset = tv.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qzf/anaconda3/envs/torch/lib/python3.7/site-packages/torch/cuda/__init__.py:135: UserWarning: \n",
      "    Found GPU0 GeForce GT 750M which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "onehot = torch.eye(label_dim, device = torch.device('cuda')).view(label_dim, label_dim, 1, 1)\n",
    "fill = torch.zeros([label_dim, label_dim, image_size, image_size], device = torch.device('cuda'))\n",
    "for i in range(label_dim):\n",
    "    fill[i, i, :, :] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(G_in_dim, label_dim, G_out_dim, num_channels)\n",
    "D = Discriminator(16, 10, 9)\n",
    "clf =  resnet_transfer()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    G, D, clf = G.cuda(), D.cuda(), clf.cuda()\n",
    "    \n",
    "optim_G = optim.Adam(G.parameters(), lr = learning_rate, betas = betas)\n",
    "optim_D = optim.RMSprop(D.parameters(), lr = learning_rate/2)\n",
    "optim_clf = optim.SGD(clf.parameters(), lr = 0.01, momentum = 0.9)\n",
    "optim_arch = optim.Adam(D.arch_parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "tensor(2.3221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0103,  0.0092, -0.0098, -0.0096,  0.0105,  0.0112, -0.0091, -0.0097],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 1\n",
      "tensor(2.5134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0194,  0.0173, -0.0116, -0.0132,  0.0152,  0.0206, -0.0189, -0.0171],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 2\n",
      "tensor(3.0918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0286,  0.0262, -0.0135, -0.0185,  0.0174,  0.0209, -0.0163, -0.0213],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 3\n",
      "tensor(2.8659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0364,  0.0312, -0.0148, -0.0220,  0.0210,  0.0239, -0.0196, -0.0250],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 4\n",
      "tensor(3.2459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0404,  0.0330, -0.0190, -0.0276,  0.0254,  0.0259, -0.0181, -0.0288],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 5\n",
      "tensor(1.8115, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0423,  0.0362, -0.0215, -0.0307,  0.0290,  0.0256, -0.0172, -0.0331],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 6\n",
      "tensor(4.3534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0443,  0.0394, -0.0235, -0.0336,  0.0326,  0.0254, -0.0175, -0.0372],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 7\n",
      "tensor(3.5080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0457,  0.0425, -0.0253, -0.0358,  0.0357,  0.0251, -0.0178, -0.0406],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 8\n",
      "tensor(3.0704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0472,  0.0452, -0.0270, -0.0374,  0.0387,  0.0250, -0.0186, -0.0439],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 9\n",
      "tensor(5.0418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0486,  0.0476, -0.0286, -0.0390,  0.0415,  0.0251, -0.0190, -0.0470],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 10\n",
      "tensor(4.0614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0488,  0.0490, -0.0306, -0.0410,  0.0444,  0.0260, -0.0195, -0.0500],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 11\n",
      "tensor(4.0371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0494,  0.0511, -0.0321, -0.0424,  0.0468,  0.0259, -0.0200, -0.0527],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 12\n",
      "tensor(3.0580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0503,  0.0531, -0.0334, -0.0438,  0.0492,  0.0262, -0.0213, -0.0548],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 13\n",
      "tensor(4.1140, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0508,  0.0543, -0.0348, -0.0456,  0.0515,  0.0269, -0.0223, -0.0566],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 14\n",
      "tensor(3.9391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0509,  0.0550, -0.0368, -0.0479,  0.0539,  0.0278, -0.0230, -0.0581],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 15\n",
      "tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0514,  0.0563, -0.0384, -0.0497,  0.0560,  0.0277, -0.0235, -0.0595],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 16\n",
      "tensor(3.7942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0521,  0.0574, -0.0395, -0.0511,  0.0579,  0.0274, -0.0243, -0.0605],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 17\n",
      "tensor(4.0780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0527,  0.0582, -0.0408, -0.0530,  0.0596,  0.0269, -0.0243, -0.0612],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 18\n",
      "tensor(2.9089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0525,  0.0584, -0.0426, -0.0554,  0.0615,  0.0274, -0.0245, -0.0619],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 19\n",
      "tensor(2.8184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0522,  0.0584, -0.0439, -0.0573,  0.0628,  0.0281, -0.0244, -0.0626],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 20\n",
      "tensor(3.7219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0520,  0.0581, -0.0451, -0.0596,  0.0645,  0.0279, -0.0242, -0.0631],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 21\n",
      "tensor(5.6016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0520,  0.0581, -0.0462, -0.0617,  0.0661,  0.0270, -0.0240, -0.0632],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 22\n",
      "tensor(3.9254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0522,  0.0581, -0.0470, -0.0631,  0.0672,  0.0255, -0.0237, -0.0629],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 23\n",
      "tensor(3.7791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0527,  0.0585, -0.0475, -0.0641,  0.0682,  0.0235, -0.0236, -0.0626],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 24\n",
      "tensor(4.6083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0530,  0.0591, -0.0480, -0.0650,  0.0691,  0.0214, -0.0235, -0.0621],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 25\n",
      "tensor(5.8520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0533,  0.0596, -0.0486, -0.0660,  0.0698,  0.0196, -0.0235, -0.0613],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 26\n",
      "tensor(6.6583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0534,  0.0594, -0.0492, -0.0670,  0.0701,  0.0184, -0.0230, -0.0603],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 27\n",
      "tensor(4.9612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0535,  0.0594, -0.0497, -0.0678,  0.0703,  0.0168, -0.0225, -0.0592],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 28\n",
      "tensor(4.3054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0536,  0.0596, -0.0499, -0.0683,  0.0703,  0.0151, -0.0222, -0.0582],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 29\n",
      "tensor(3.9528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0537,  0.0599, -0.0501, -0.0687,  0.0703,  0.0136, -0.0220, -0.0572],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 30\n",
      "tensor(5.9053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0538,  0.0599, -0.0507, -0.0695,  0.0704,  0.0124, -0.0216, -0.0561],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 31\n",
      "tensor(7.1665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0538,  0.0599, -0.0514, -0.0703,  0.0704,  0.0113, -0.0209, -0.0553],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 32\n",
      "tensor(5.8419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0534,  0.0593, -0.0523, -0.0715,  0.0710,  0.0109, -0.0205, -0.0546],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 33\n",
      "tensor(5.3512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0534,  0.0593, -0.0527, -0.0721,  0.0713,  0.0098, -0.0203, -0.0540],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 34\n",
      "tensor(3.9152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0525,  0.0586, -0.0535, -0.0732,  0.0717,  0.0093, -0.0198, -0.0534],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 35\n",
      "tensor(4.1648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0522,  0.0588, -0.0539, -0.0738,  0.0719,  0.0079, -0.0197, -0.0525],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 36\n",
      "tensor(5.8665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0519,  0.0600, -0.0534, -0.0733,  0.0721,  0.0061, -0.0206, -0.0522],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 37\n",
      "tensor(6.3972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0523,  0.0610, -0.0523, -0.0719,  0.0720,  0.0041, -0.0222, -0.0514],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 38\n",
      "tensor(4.7734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0524,  0.0614, -0.0518, -0.0714,  0.0724,  0.0031, -0.0233, -0.0511],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 39\n",
      "tensor(6.9276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0526,  0.0620, -0.0513, -0.0710,  0.0728,  0.0020, -0.0243, -0.0508],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 40\n",
      "tensor(2.9654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0528,  0.0624, -0.0511, -0.0706,  0.0734,  0.0009, -0.0254, -0.0506],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 41\n",
      "tensor(5.9048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-5.2626e-02,  6.2572e-02, -5.1080e-02, -7.0284e-02,  7.3938e-02,\n",
      "         2.5060e-05, -2.6264e-02, -5.0415e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "0 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0527,  0.0628, -0.0509, -0.0699,  0.0747, -0.0009, -0.0274, -0.0503],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 43\n",
      "tensor(4.5220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0528,  0.0634, -0.0504, -0.0694,  0.0753, -0.0020, -0.0286, -0.0504],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 44\n",
      "tensor(5.1960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0528,  0.0639, -0.0500, -0.0687,  0.0757, -0.0029, -0.0299, -0.0502],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 45\n",
      "tensor(2.6456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0527,  0.0643, -0.0497, -0.0682,  0.0761, -0.0035, -0.0310, -0.0501],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 46\n",
      "tensor(3.3418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0526,  0.0646, -0.0493, -0.0675,  0.0763, -0.0041, -0.0320, -0.0498],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 47\n",
      "tensor(6.0009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0526,  0.0650, -0.0489, -0.0669,  0.0762, -0.0044, -0.0330, -0.0494],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 48\n",
      "tensor(7.3862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0523,  0.0651, -0.0489, -0.0666,  0.0761, -0.0044, -0.0336, -0.0492],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 49\n",
      "tensor(4.8250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0522,  0.0656, -0.0489, -0.0660,  0.0760, -0.0046, -0.0341, -0.0491],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 50\n",
      "tensor(3.5292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0524,  0.0663, -0.0482, -0.0649,  0.0761, -0.0048, -0.0351, -0.0496],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 51\n",
      "tensor(3.0774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0523,  0.0672, -0.0475, -0.0637,  0.0763, -0.0053, -0.0359, -0.0507],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 52\n",
      "tensor(4.0698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0521,  0.0681, -0.0466, -0.0625,  0.0767, -0.0053, -0.0368, -0.0523],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 53\n",
      "tensor(3.0257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0521,  0.0694, -0.0456, -0.0613,  0.0769, -0.0058, -0.0376, -0.0538],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 54\n",
      "tensor(2.7484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0519,  0.0707, -0.0448, -0.0604,  0.0772, -0.0062, -0.0386, -0.0550],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 55\n",
      "tensor(4.5011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0518,  0.0716, -0.0441, -0.0597,  0.0774, -0.0067, -0.0393, -0.0560],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 56\n",
      "tensor(9.8706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0515,  0.0721, -0.0436, -0.0591,  0.0777, -0.0070, -0.0398, -0.0568],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 57\n",
      "tensor(4.9438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0511,  0.0726, -0.0431, -0.0585,  0.0779, -0.0072, -0.0404, -0.0575],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 58\n",
      "tensor(4.2004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0505,  0.0727, -0.0427, -0.0580,  0.0782, -0.0073, -0.0410, -0.0582],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 59\n",
      "tensor(7.1534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0494,  0.0723, -0.0428, -0.0580,  0.0787, -0.0066, -0.0418, -0.0587],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 60\n",
      "tensor(5.5771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0481,  0.0721, -0.0427, -0.0577,  0.0790, -0.0062, -0.0427, -0.0588],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 61\n",
      "tensor(5.5401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0469,  0.0717, -0.0425, -0.0576,  0.0794, -0.0055, -0.0440, -0.0590],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 62\n",
      "tensor(3.1938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0450,  0.0702, -0.0430, -0.0580,  0.0803, -0.0040, -0.0449, -0.0593],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 63\n",
      "tensor(3.1152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0428,  0.0692, -0.0435, -0.0585,  0.0807, -0.0032, -0.0460, -0.0588],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 64\n",
      "tensor(2.8931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0409,  0.0685, -0.0440, -0.0588,  0.0812, -0.0026, -0.0469, -0.0584],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 65\n",
      "tensor(7.9743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0396,  0.0680, -0.0443, -0.0589,  0.0816, -0.0020, -0.0479, -0.0582],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 66\n",
      "tensor(3.2549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0381,  0.0675, -0.0448, -0.0589,  0.0819, -0.0013, -0.0487, -0.0581],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 67\n",
      "tensor(3.4019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0358,  0.0665, -0.0454, -0.0594,  0.0820, -0.0010, -0.0486, -0.0579],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 68\n",
      "tensor(4.1068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0341,  0.0661, -0.0457, -0.0595,  0.0819, -0.0016, -0.0487, -0.0571],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 69\n",
      "tensor(3.7960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0326,  0.0655, -0.0464, -0.0599,  0.0821, -0.0022, -0.0487, -0.0562],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 70\n",
      "tensor(5.9474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0313,  0.0652, -0.0468, -0.0602,  0.0819, -0.0035, -0.0487, -0.0548],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 71\n",
      "tensor(5.4153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0301,  0.0648, -0.0473, -0.0607,  0.0819, -0.0051, -0.0487, -0.0531],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 72\n",
      "tensor(5.3227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0290,  0.0643, -0.0478, -0.0610,  0.0821, -0.0065, -0.0485, -0.0519],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 73\n",
      "tensor(3.7464, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0280,  0.0638, -0.0483, -0.0616,  0.0822, -0.0074, -0.0486, -0.0508],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 74\n",
      "tensor(2.5742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0268,  0.0633, -0.0489, -0.0624,  0.0824, -0.0080, -0.0485, -0.0498],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 75\n",
      "tensor(3.9506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0256,  0.0630, -0.0496, -0.0629,  0.0825, -0.0083, -0.0482, -0.0495],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 76\n",
      "tensor(3.5308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0242,  0.0625, -0.0503, -0.0635,  0.0829, -0.0085, -0.0481, -0.0491],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 77\n",
      "tensor(2.8752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0230,  0.0619, -0.0511, -0.0642,  0.0836, -0.0088, -0.0482, -0.0488],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 78\n",
      "tensor(9.5218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0220,  0.0617, -0.0519, -0.0649,  0.0843, -0.0097, -0.0487, -0.0482],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 79\n",
      "tensor(4.6863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([-0.0210,  0.0614, -0.0528, -0.0657,  0.0849, -0.0105, -0.0489, -0.0472],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "0 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/qzf/anaconda3/envs/torch/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/qzf/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/qzf/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/qzf/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0592b4e67232>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mD_running_real_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mD_real_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mD_running_fake_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mD_fake_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mD_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0moptim_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "G.train()\n",
    "D.train()\n",
    "clf.train()\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "while epoch < num_epochs:\n",
    "    #print(epoch+1)\n",
    "    G_running_loss = 0.0\n",
    "    D_running_real_loss = 0.0\n",
    "    D_running_fake_loss = 0.0\n",
    "    \n",
    "    for i, ((images, labels), (val_images, val_labels)) in enumerate(zip(trainloader, valloader)):\n",
    "        print(epoch, i)\n",
    "        mini_batch = images.size()[0]\n",
    "        x_ = images.cuda(non_blocking = True)\n",
    "        val_images, val_labels = val_images.cuda(non_blocking = True), val_labels.cuda(non_blocking = True)\n",
    "        \n",
    "        y_real_ = torch.ones(mini_batch, device = torch.device('cuda'))\n",
    "        y_fake_ = torch.zeros(mini_batch, device = torch.device('cuda'))\n",
    "        c_fill_ = fill[labels]\n",
    "        \n",
    "        # Train discriminator\n",
    "        optim_D.zero_grad()\n",
    "        D_real_decision = D(x_, c_fill_).squeeze()\n",
    "        D_real_loss = D.loss(D_real_decision, y_real_)\n",
    "\n",
    "        z_ = torch.randn(mini_batch, G_in_dim, device = torch.device('cuda')).view(-1, G_in_dim, 1, 1)\n",
    "        c_ = (torch.rand(mini_batch, 1) * label_dim).type(torch.LongTensor).squeeze()\n",
    "        c_onehot_ = onehot[c_]\n",
    "        gen_image = G(z_, c_onehot_)\n",
    "        \n",
    "        c_fill_ = fill[c_]\n",
    "        D_fake_decision = D(gen_image, c_fill_).squeeze()\n",
    "        D_fake_loss = D.loss(D_fake_decision, y_fake_)\n",
    "        \n",
    "        D_loss = D_real_loss + D_fake_loss\n",
    "        D_running_real_loss += D_real_loss.item()\n",
    "        D_running_fake_loss += D_fake_loss.item()\n",
    "        D_loss.backward()\n",
    "        optim_D.step()\n",
    "        \n",
    "        # Train generator\n",
    "        z_ = torch.randn(mini_batch, G_in_dim, device = torch.device('cuda')).view(-1, G_in_dim, 1, 1)\n",
    "        c_ = (torch.rand(mini_batch, 1) * label_dim).type(torch.LongTensor).squeeze()\n",
    "        c_onehot_ = onehot[c_]\n",
    "        \n",
    "        optim_G.zero_grad()\n",
    "        optim_arch.zero_grad()\n",
    "        gen_image = G(z_, c_onehot_)\n",
    "\n",
    "        c_fill_ = fill[c_]\n",
    "        D_fake_decision = D(gen_image, c_fill_).squeeze()\n",
    "        G_loss = G.loss(D_fake_decision, y_real_)\n",
    "        G_running_loss += G_loss.item()\n",
    "\n",
    "        #grad = torch.autograd.grad(G_loss, D.arch_parameters(), create_graph = True)\n",
    "        G_loss.backward(create_graph = True)\n",
    "        optim_G.step()\n",
    "        \n",
    "        # Train Resnet\n",
    "        z_ = torch.randn(mini_batch, G_in_dim, device = torch.device('cuda')).view(-1, G_in_dim, 1, 1)\n",
    "        c_ = (torch.rand(mini_batch, 1) * label_dim).type(torch.LongTensor).squeeze()\n",
    "        c_onehot_ = onehot[c_]\n",
    "        \n",
    "        c_ = c_.cuda(non_blocking = True)\n",
    "        labels = labels.cuda(non_blocking = True)\n",
    "        \n",
    "        gen_image = G(z_, c_onehot_)\n",
    "        \n",
    "        optim_clf.zero_grad()\n",
    "        clf_fake_decision = clf(gen_image)\n",
    "        clf_fake_loss = clf.loss(clf_fake_decision, c_)      \n",
    "        clf_real_decision = clf(x_)\n",
    "        clf_real_loss = clf.loss(clf_real_decision, labels)\n",
    "        \n",
    "        clf_loss = clf_fake_loss + clf_real_loss\n",
    "        clf_loss.backward(create_graph = True)\n",
    "        optim_clf.step()\n",
    "        \n",
    "        # Train architecture\n",
    "        y = clf(val_images)\n",
    "        loss = clf.loss(y, val_labels)\n",
    "        loss.backward()\n",
    "        optim_arch.step()\n",
    "        \n",
    "        \n",
    "        print(loss)\n",
    "        print(D.alphas_normal[0])\n",
    "        for param in G.parameters():\n",
    "            param.grad = None\n",
    "        for param in D.parameters():\n",
    "            param.grad = None\n",
    "        for param in clf.parameters():\n",
    "            param.grad = None\n",
    "        for param in D.arch_parameters():\n",
    "            param.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
